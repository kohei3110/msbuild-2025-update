{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-projects azure-identity azure-ai-evaluation azure-ai-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d302bd",
   "metadata": {},
   "source": [
    "以下の環境変数をセット。\n",
    "\n",
    "- PROJECT_CONNECTION_STRING - The project connection string, as found in the overview page of your Azure AI Foundry project.\n",
    "- MODEL_DEPLOYMENT_NAME - The deployment name of the model for AI-assisted evaluators, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "- AZURE_OPENAI_ENDPOINT - Azure Open AI Endpoint to be used for evaluation.\n",
    "- AZURE_OPENAI_API_KEY - Azure Open AI Key to be used for evaluation.\n",
    "- AZURE_OPENAI_API_VERSION - Azure Open AI Api version to be used for evaluation.\n",
    "- AZURE_SUBSCRIPTION_ID - Azure Subscription Id of Azure AI Project\n",
    "- PROJECT_NAME - Azure AI Project Name\n",
    "- RESOURCE_GROUP_NAME - Azure AI Project Resource Group Name\n",
    "- AGENT_MODEL_DEPLOYMENT_NAME - The deployment name of the model for your Azure AI agent, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5208112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c096a",
   "metadata": {},
   "source": [
    "## Initialize Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import FunctionTool, ToolSet, AgentThreadCreationOptions\n",
    "from user_functions import user_functions\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.environ[\"PROJECT_URL\"],\n",
    ")\n",
    "\n",
    "AGENT_NAME = \"Seattle Tourist Assistant\"\n",
    "\n",
    "# Add Tools to be used by Agent\n",
    "functions = FunctionTool(user_functions)\n",
    "\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d3d9b",
   "metadata": {},
   "source": [
    "### AI Foundry Agent Service の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = project_client.agents.create_agent(\n",
    "    model=os.environ[\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\"],\n",
    "    name=AGENT_NAME,\n",
    "    instructions=\"You are helpful agent\",\n",
    "    toolset=toolset,\n",
    ")\n",
    "print(f\"Created agent, agent ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76027c34",
   "metadata": {},
   "source": [
    "### Thread 作成、実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a318b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_run = project_client.agents.create_thread_and_process_run(\n",
    "    agent_id=agent.id,\n",
    "    thread=AgentThreadCreationOptions(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What are some good places to visit in Seattle?\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(f\"Thread run status: {thread_run.status}\")\n",
    "\n",
    "for message in project_client.agents.messages.list(thread_run.thread_id):\n",
    "    print(f\"Role: {message.role}, Content: {message.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a00c2",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdba4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import AIAgentConverter\n",
    "\n",
    "# Initialize the converter that will be backed by the project.\n",
    "converter = AIAgentConverter(project_client)\n",
    "\n",
    "thread_id = thread_run.thread_id\n",
    "run_id = thread_run.id\n",
    "file_name = \"evaluation_data.jsonl\"\n",
    "\n",
    "# Get a single agent run data\n",
    "evaluation_data_single_run = converter.convert(thread_id=thread_id, run_id=run_id)\n",
    "print(f\"Single run evaluation data: {evaluation_data_single_run}\")\n",
    "evaluation_data = converter.prepare_evaluation_data(thread_ids=thread_id, filename=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ae456",
   "metadata": {},
   "source": [
    "### evaluator のセットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import (\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    AzureOpenAIModelConfiguration,\n",
    "    IntentResolutionEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "# Needed to use content safety evaluators\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    \"project_name\": os.environ[\"PROJECT_NAME\"],\n",
    "    \"resource_group_name\": os.environ[\"RESOURCE_GROUP_NAME\"],\n",
    "}\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n",
    "\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "\n",
    "task_adherence = TaskAdherenceEvaluator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "response = evaluate(\n",
    "    data=file_name,\n",
    "    evaluators={\n",
    "        \"tool_call_accuracy\": tool_call_accuracy,\n",
    "        \"intent_resolution\": intent_resolution,\n",
    "        \"task_adherence\": task_adherence,\n",
    "    },\n",
    "    azure_ai_project={\n",
    "        \"subscription_id\": os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "        \"project_name\": os.environ[\"PROJECT_NAME\"],\n",
    "        \"resource_group_name\": os.environ[\"RESOURCE_GROUP_NAME\"],\n",
    "    },\n",
    ")\n",
    "pprint(f'AI Foundary URL: {response.get(\"studio_url\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import AgentEvaluation, AgentEvaluationRequest\n",
    "\n",
    "\n",
    "eval_job: AgentEvaluation = project_client.evaluations.create_agent_evaluation(\n",
    "    evaluation=AgentEvaluationRequest(\n",
    "        evaluators={\n",
    "            \n",
    "        },\n",
    "        run_id=run_id\n",
    "    )\n",
    ")\n",
    "print(f\"Evaluation job created with ID: {eval_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18319857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from azure.ai.projects.models import (\n",
    "    AgentEvaluationRequest,\n",
    "    EvaluatorIds,\n",
    "    EvaluatorConfiguration,\n",
    "    AgentEvaluationSamplingConfiguration,\n",
    "    AgentEvaluationRedactionConfiguration,\n",
    ")\n",
    "\n",
    "\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "            thread_id=thread.id, role=\"user\", content=\"Hello, tell me a joke\"\n",
    "        )\n",
    "print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "run = project_client.agents.runs.create(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    # Wait for a second\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"Run status: {run.status}\")\n",
    "\n",
    "agent_evaluation_request = AgentEvaluationRequest(\n",
    "    run_id=run.id,\n",
    "    thread_id=thread.id,\n",
    "    evaluators={\n",
    "        \"violence\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.VIOLENCE,\n",
    "        )\n",
    "    },\n",
    "    sampling_configuration=AgentEvaluationSamplingConfiguration(\n",
    "        name=\"test\",\n",
    "        sampling_percent=100,\n",
    "        max_request_rate=100,\n",
    "    ),\n",
    "    redaction_configuration=AgentEvaluationRedactionConfiguration(\n",
    "        redact_score_properties=False,\n",
    "    ),\n",
    "    app_insights_connection_string=project_client.telemetry.get_connection_string(),\n",
    ")\n",
    "\n",
    "agent_evaluation_response = project_client.evaluations.create_agent_evaluation(\n",
    "    evaluation=agent_evaluation_request\n",
    ")\n",
    "\n",
    "print(agent_evaluation_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f508ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Get an authenticated Azure OpenAI client for the parent AI Services resource, and perform a chat completion operation:\"\n",
    ")\n",
    "with project_client.inference.get_azure_openai_client(api_version=\"2024-10-21\") as client:\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How many feet are in a mile?\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
