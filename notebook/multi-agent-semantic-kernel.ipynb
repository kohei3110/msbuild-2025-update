{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005872b2",
   "metadata": {},
   "source": [
    "# Semantic Kernelを使用したマルチエージェントシステム\n",
    "\n",
    "このノートブックでは、Microsoft Semantic Kernelを使用してマルチエージェントシステムを構築する方法を説明します。\n",
    "\n",
    "## 概要\n",
    "\n",
    "本システムでは以下の3つのエージェントが協調して動作します：\n",
    "\n",
    "1. **リサーチャーエージェント**: Bing検索を使用して市場調査を行う専門家\n",
    "2. **ライターエージェント**: 調査結果をマークダウン形式のレポートにまとめる技術ライター\n",
    "3. **コーディネーターエージェント**: ユーザーのクエリを分析し、適切なエージェントに作業を振り分ける\n",
    "\n",
    "## 技術スタック\n",
    "\n",
    "- **Semantic Kernel**: Microsoftが開発するAIアプリケーション開発フレームワーク\n",
    "- **Azure OpenAI Service**: 大規模言語モデルの実行基盤\n",
    "- **Azure AI Projects**: エージェント管理とBing検索機能\n",
    "- **Python**: プログラミング言語"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b348ceb",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインストール\n",
    "\n",
    "Semantic KernelとAzure AI Projectsライブラリをインストールします。これらのライブラリは以下の機能を提供します：\n",
    "\n",
    "- `semantic-kernel`: AIエージェントの作成と管理\n",
    "- `azure-ai-projects`: Azure AI Projectsサービスとの連携（Bing検索など）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮想環境内でパッケージをインストール\n",
    "import sys\n",
    "!{sys.executable} -m pip install semantic-kernel azure-ai-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54549922",
   "metadata": {},
   "source": [
    "## 環境変数の読み込み\n",
    "\n",
    "Azure OpenAIやAzure AI Projectsの接続情報を`.env`ファイルから読み込みます。\n",
    "\n",
    "必要な環境変数：\n",
    "- `AZURE_OPENAI_ENDPOINT`: Azure OpenAIサービスのエンドポイント\n",
    "- `AZURE_OPENAI_API_KEY`: Azure OpenAIのAPIキー\n",
    "- `AZURE_OPENAI_API_VERSION`: 使用するAPIのバージョン\n",
    "- `AGENT_MODEL_DEPLOYMENT_NAME`: デプロイされたモデル名\n",
    "- `PROJECT_CONNECTION_STRING`: Azure AI Projectsの接続文字列\n",
    "- `BING_CONNECTION_NAME`: Bing検索の接続名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../concierge-agent/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0deffdd",
   "metadata": {},
   "source": [
    "ユーティリティ関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f73be",
   "metadata": {},
   "source": [
    "### 主要な関数の説明\n",
    "\n",
    "1. **`print_thread_message_details`**: \n",
    "   - エージェント間の会話履歴を詳細に表示\n",
    "   - 関数呼び出し、結果、テキストメッセージを区別して表示\n",
    "   - JSON形式のデータを自動でデコードして見やすく整形\n",
    "\n",
    "2. **`log_with_timestamp`**:\n",
    "   - タイムスタンプ付きでログメッセージを出力\n",
    "   - デバッグ時の時系列把握に有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db937586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "from semantic_kernel.contents.text_content import TextContent\n",
    "\n",
    "\n",
    "async def print_thread_message_details(thread: str):\n",
    "    \"\"\"\n",
    "    スレッドのメッセージ詳細を表示します。\n",
    "\n",
    "    Args:\n",
    "        thread (str): スレッドのインスタンス\n",
    "    \"\"\"\n",
    "    async for message in thread.get_messages():\n",
    "        print(\"-----\")\n",
    "\n",
    "        for item in message.items:\n",
    "            if isinstance(item, FunctionCallContent):\n",
    "                print(f\"[Function Calling] by {message.ai_model_id}\")\n",
    "                print(f\" - Function Name : {item.name}\")\n",
    "                print(f\" - Arguments     : {item.arguments}\")\n",
    "\n",
    "            elif isinstance(item, FunctionResultContent):\n",
    "                print(f\"[Function Result]\")\n",
    "                # 文字列のデコード変換\n",
    "                if isinstance(item.result, str):\n",
    "                    try:\n",
    "                        decoded = json.loads(item.result)\n",
    "                        print(f\" - Result        : {decoded}\") # デコード成功時は変換後の値を表示\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\" - Result        : {item.result}\")  # デコード失敗時はそのまま\n",
    "                else:\n",
    "                    print(f\" - Result        : {item.result}\")\n",
    "\n",
    "            elif isinstance(item, TextContent):\n",
    "                if message.name:\n",
    "                    print(f\"[Agent Response] from {message.ai_model_id}\")\n",
    "                else:\n",
    "                    print(\"[User Message]\")\n",
    "                print(f\" - Content       : {item.text}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"[Unknown Item Type] ({type(item).__name__})\")\n",
    "                print(f\" - Raw Item      : {item}\")\n",
    "\n",
    "\n",
    "def log_with_timestamp(message: str) -> None:\n",
    "    \"\"\"\n",
    "    現在時刻付きでメッセージを標準出力にログとして表示します。\n",
    "\n",
    "    Args:\n",
    "        message (str): 出力するログメッセージ。\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "    print(f\"[{timestamp}] {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3cd0f",
   "metadata": {},
   "source": [
    "## マルチエージェントシステムの実装\n",
    "\n",
    "ここからがメインの実装部分です。以下の要素を含みます：\n",
    "\n",
    "1. **SearchPlugin**: Bing検索と日付操作の機能を提供\n",
    "2. **エージェント定義**: 3つの専門エージェントの作成\n",
    "3. **対話処理**: ユーザーとの会話とエージェント間の協調処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel import Kernel\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- プラグイン定義 ---\n",
    "class SearchPlugin:\n",
    "    @kernel_function(description=\"Bing 検索結果を要約\")\n",
    "    def web_search(self, query: str) -> str:\n",
    "        project_client = AIProjectClient(\n",
    "            endpoint=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    "            credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    "        )\n",
    "        conn_id = os.environ[\"BING_CONNECTION_NAME\"]  # Ensure the BING_CONNECTION_NAME environment variable is set\n",
    "\n",
    "        # Initialize the Bing Grounding tool\n",
    "        bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "        with project_client:\n",
    "            # Create an agent with the Bing Grounding tool\n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],  # Model deployment name\n",
    "                name=\"my-agent\",  # Name of the agent\n",
    "                instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "                tools=bing.definitions,  # Attach the Bing Grounding tool\n",
    "            )\n",
    "            print(f\"Created agent, ID: {agent.id}\")\n",
    "            thread = project_client.agents.threads.create()\n",
    "            print(f\"Created thread, ID: {thread.id}\")\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",  # Role of the message sender\n",
    "                content=query,  # Message content\n",
    "            )\n",
    "            run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "            messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "            for message in messages:\n",
    "                print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "                return message.content[-1].text.value  # Return the content of the last message\n",
    "        # TODO: 失敗した場合のエラーハンドリング\n",
    "        return f\"検索結果: {query} に関する情報\"\n",
    "\n",
    "    @kernel_function(description=\"今日の日付をYYYY-MM-DD形式で返します。\")\n",
    "    def get_today(self) -> Annotated[str, \"YYYY-MM-DD形式でフォーマットされた現在の日付。\"]:\n",
    "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    @kernel_function(description=\"日数のオフセットに基づいて相対的な日付を返します。\")\n",
    "    def get_relative_date(self, days_offset: Annotated[int, \"今日に追加する日数。\"]) -> Annotated[str, \"今日からオフセットされた日付をYYYY-MM-DD形式で。\"]:\n",
    "        return (datetime.now() + timedelta(days=days_offset)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "# --- エージェント設定 ---\n",
    "def create_agents():\n",
    "    # Kernelの作成\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    # Azure OpenAI サービスの追加\n",
    "    chat_service = AzureChatCompletion(\n",
    "        deployment_name=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    )\n",
    "    kernel.add_service(chat_service)\n",
    "    \n",
    "    # プラグインの追加\n",
    "    kernel.add_plugin(SearchPlugin(), plugin_name=\"search\")\n",
    "    \n",
    "    # リサーチャーエージェント\n",
    "    researcher = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"ResearcherAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたは市場調査の専門家です。与えられたクエリに対して検索を行い、\n",
    "        結果を日本語で要約してください。\n",
    "        \"\"\",\n",
    "    )\n",
    "    \n",
    "    # ライターエージェント\n",
    "    writer = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"WriterAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたは技術ライターです。リサーチ結果を受け取り、\n",
    "        マークダウン形式のレポートを作成してください。\n",
    "        \"\"\",\n",
    "    )\n",
    "    \n",
    "    # コーディネーターエージェント\n",
    "    coordinator = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"CoordinatorAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたはエージェントコーディネーターです。\n",
    "        ユーザーのクエリに対して、リサーチが必要かどうかを判断し、\n",
    "        必要に応じて適切なエージェントに作業を依頼してください。\n",
    "        \"\"\",\n",
    "        plugins=[researcher, writer],\n",
    "    )\n",
    "    \n",
    "    return coordinator\n",
    "\n",
    "# --- 対話処理 ---\n",
    "async def handle_conversation():\n",
    "    coordinator = create_agents()\n",
    "    \n",
    "    print(\"🤖 マルチエージェントシステムが起動しました\")\n",
    "    print(\"終了するには 'exit' と入力してください\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User> \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"終了\"]:\n",
    "            break\n",
    "\n",
    "        from semantic_kernel.agents import ChatHistoryAgentThread\n",
    "        thread = ChatHistoryAgentThread()\n",
    "        response = await coordinator.get_response(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        )\n",
    "        await print_thread_message_details(thread)\n",
    "        print(f\"CoordinatorAgent> {response.content}\")\n",
    "    \n",
    "    print(\"セッション終了\")\n",
    "\n",
    "# 非同期関数を実行\n",
    "await handle_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15a1ce",
   "metadata": {},
   "source": [
    "## 使用方法とヒント\n",
    "\n",
    "### 効果的な質問例\n",
    "\n",
    "1. **市場調査系**:\n",
    "   - \"2024年のAI市場の動向を調査して\"\n",
    "   - \"競合他社のマーケティング戦略を分析して\"\n",
    "\n",
    "2. **技術トレンド系**:\n",
    "   - \"最新のクラウド技術のトレンドをまとめて\"\n",
    "   - \"機械学習の新しい手法について調べて\"\n",
    "\n",
    "3. **製品・サービス分析**:\n",
    "   - \"Microsoft Copilotの機能と競合比較\"\n",
    "   - \"SaaSプラットフォームの価格動向\"\n",
    "\n",
    "### システムの特徴\n",
    "\n",
    "- **協調的処理**: 複数のエージェントが役割分担して作業\n",
    "- **リアルタイム検索**: Bing APIを使用した最新情報の取得\n",
    "- **構造化出力**: マークダウン形式での見やすいレポート生成\n",
    "- **詳細ログ**: 処理過程の可視化によるデバッグ支援\n",
    "\n",
    "### 注意事項\n",
    "\n",
    "- 検索結果の精度はBing APIの性能に依存します\n",
    "- 大量の検索を行う場合はAPI制限に注意してください\n",
    "- 重要な判断には複数の情報源での確認を推奨します"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
