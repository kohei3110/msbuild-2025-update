{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮想環境内でパッケージをインストール\n",
    "import sys\n",
    "!{sys.executable} -m pip install semantic-kernel azure-ai-projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../concierge-agent/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0deffdd",
   "metadata": {},
   "source": [
    "ユーティリティ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db937586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "from semantic_kernel.contents.text_content import TextContent\n",
    "\n",
    "\n",
    "async def print_thread_message_details(thread: str):\n",
    "    \"\"\"\n",
    "    スレッドのメッセージ詳細を表示します。\n",
    "\n",
    "    Args:\n",
    "        thread (str): スレッドのインスタンス\n",
    "    \"\"\"\n",
    "    async for message in thread.get_messages():\n",
    "        print(\"-----\")\n",
    "\n",
    "        for item in message.items:\n",
    "            if isinstance(item, FunctionCallContent):\n",
    "                print(f\"[Function Calling] by {message.ai_model_id}\")\n",
    "                print(f\" - Function Name : {item.name}\")\n",
    "                print(f\" - Arguments     : {item.arguments}\")\n",
    "\n",
    "            elif isinstance(item, FunctionResultContent):\n",
    "                print(f\"[Function Result]\")\n",
    "                # 文字列のデコード変換\n",
    "                if isinstance(item.result, str):\n",
    "                    try:\n",
    "                        decoded = json.loads(item.result)\n",
    "                        print(f\" - Result        : {decoded}\") # デコード成功時は変換後の値を表示\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\" - Result        : {item.result}\")  # デコード失敗時はそのまま\n",
    "                else:\n",
    "                    print(f\" - Result        : {item.result}\")\n",
    "\n",
    "            elif isinstance(item, TextContent):\n",
    "                if message.name:\n",
    "                    print(f\"[Agent Response] from {message.ai_model_id}\")\n",
    "                else:\n",
    "                    print(\"[User Message]\")\n",
    "                print(f\" - Content       : {item.text}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"[Unknown Item Type] ({type(item).__name__})\")\n",
    "                print(f\" - Raw Item      : {item}\")\n",
    "\n",
    "\n",
    "def log_with_timestamp(message: str) -> None:\n",
    "    \"\"\"\n",
    "    現在時刻付きでメッセージを標準出力にログとして表示します。\n",
    "\n",
    "    Args:\n",
    "        message (str): 出力するログメッセージ。\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n",
    "    print(f\"[{timestamp}] {message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel import Kernel\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- プラグイン定義 ---\n",
    "class SearchPlugin:\n",
    "    @kernel_function(description=\"Bing 検索結果を要約\")\n",
    "    def web_search(self, query: str) -> str:\n",
    "        project_client = AIProjectClient(\n",
    "            endpoint=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    "            credential=DefaultAzureCredential(),  # Use Azure Default Credential for authentication\n",
    "        )\n",
    "        conn_id = os.environ[\"BING_CONNECTION_NAME\"]  # Ensure the BING_CONNECTION_NAME environment variable is set\n",
    "\n",
    "        # Initialize the Bing Grounding tool\n",
    "        bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "        with project_client:\n",
    "            # Create an agent with the Bing Grounding tool\n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],  # Model deployment name\n",
    "                name=\"my-agent\",  # Name of the agent\n",
    "                instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "                tools=bing.definitions,  # Attach the Bing Grounding tool\n",
    "            )\n",
    "            print(f\"Created agent, ID: {agent.id}\")\n",
    "            thread = project_client.agents.threads.create()\n",
    "            print(f\"Created thread, ID: {thread.id}\")\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",  # Role of the message sender\n",
    "                content=query,  # Message content\n",
    "            )\n",
    "            run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "            messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "            for message in messages:\n",
    "                print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "                return message.content[-1].text.value  # Return the content of the last message\n",
    "        # TODO: 失敗した場合のエラーハンドリング\n",
    "        return f\"検索結果: {query} に関する情報\"\n",
    "\n",
    "    @kernel_function(description=\"今日の日付をYYYY-MM-DD形式で返します。\")\n",
    "    def get_today(self) -> Annotated[str, \"YYYY-MM-DD形式でフォーマットされた現在の日付。\"]:\n",
    "        return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    @kernel_function(description=\"日数のオフセットに基づいて相対的な日付を返します。\")\n",
    "    def get_relative_date(self, days_offset: Annotated[int, \"今日に追加する日数。\"]) -> Annotated[str, \"今日からオフセットされた日付をYYYY-MM-DD形式で。\"]:\n",
    "        return (datetime.now() + timedelta(days=days_offset)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "# --- エージェント設定 ---\n",
    "def create_agents():\n",
    "    # Kernelの作成\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    # Azure OpenAI サービスの追加\n",
    "    chat_service = AzureChatCompletion(\n",
    "        deployment_name=os.environ[\"AGENT_MODEL_DEPLOYMENT_NAME\"],\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    )\n",
    "    kernel.add_service(chat_service)\n",
    "    \n",
    "    # プラグインの追加\n",
    "    kernel.add_plugin(SearchPlugin(), plugin_name=\"search\")\n",
    "    \n",
    "    # リサーチャーエージェント\n",
    "    researcher = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"ResearcherAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたは市場調査の専門家です。与えられたクエリに対して検索を行い、\n",
    "        結果を日本語で要約してください。\n",
    "        \"\"\",\n",
    "    )\n",
    "    \n",
    "    # ライターエージェント\n",
    "    writer = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"WriterAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたは技術ライターです。リサーチ結果を受け取り、\n",
    "        マークダウン形式のレポートを作成してください。\n",
    "        \"\"\",\n",
    "    )\n",
    "    \n",
    "    # コーディネーターエージェント\n",
    "    coordinator = ChatCompletionAgent(\n",
    "        id=\"default\",\n",
    "        kernel=kernel,\n",
    "        name=\"CoordinatorAgent\",\n",
    "        instructions=\"\"\"\n",
    "        あなたはエージェントコーディネーターです。\n",
    "        ユーザーのクエリに対して、リサーチが必要かどうかを判断し、\n",
    "        必要に応じて適切なエージェントに作業を依頼してください。\n",
    "        \"\"\",\n",
    "        plugins=[researcher, writer],\n",
    "    )\n",
    "    \n",
    "    return coordinator\n",
    "\n",
    "# --- 対話処理 ---\n",
    "async def handle_conversation():\n",
    "    coordinator = create_agents()\n",
    "    \n",
    "    print(\"🤖 マルチエージェントシステムが起動しました\")\n",
    "    print(\"終了するには 'exit' と入力してください\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User> \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"終了\"]:\n",
    "            break\n",
    "\n",
    "        from semantic_kernel.agents import ChatHistoryAgentThread\n",
    "        thread = ChatHistoryAgentThread()\n",
    "        response = await coordinator.get_response(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        )\n",
    "        await print_thread_message_details(thread)\n",
    "        print(f\"CoordinatorAgent> {response.content}\")\n",
    "    \n",
    "    print(\"セッション終了\")\n",
    "\n",
    "# 非同期関数を実行\n",
    "await handle_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
